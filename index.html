<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>The Hamming Machine</title>
<meta name="author" content="(Tammo Rukat)"/>

<link rel="stylesheet" href="./css/reveal.css"/>
<link rel="stylesheet" href="./css/theme/sky.css" id="theme"/>
<link rel="stylesheet" href="./local.css"/>
<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = '/home/tammo/Dropbox/templates/org_reveal_presentation/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>The Hamming Machine</h1>
<h2>Tammo Rukat</h2>
<h2>September 7, 2016</h2>
</section>
<section id="table-of-contents">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#/slide-sec-1">Introducing the Hamming Machine</a></li>
<li><a href="#/slide-sec-2">Synthetic example: Calculator digits</a></li>
<li><a href="#/slide-sec-3">The multi-layer Hamming Machine</a></li>
<li><a href="#/slide-sec-4">Inference and learning</a></li>
<li><a href="#/slide-sec-5">Priors on the codes</a></li>
<li><a href="#/slide-sec-6">Cancer mutational landscapes</a></li>
<li><a href="#/slide-sec-7">The sparse Hamming Machine</a></li>
<li><a href="#/slide-sec-8">Future work</a></li>
<li><a href="#/slide-sec-9">Appendix A: Further example &#x2013; MNIST</a></li>
</ul>
</div>
</div>
</section>

<section>
<section id="slide-sec-1">
<h2 id="sec-1">Introducing the Hamming Machine</h2>
</section>
<section id="slide-sec-1-1">
<h3 id="sec-1-1">Notation</h3>
<ul>
<li>Indices
<ul>
<li>\({d = 1\ldots D\; \text{- features}}\)</li>
<li>\({n = 1\ldots N\; \text{- observations/specimens}}\)</li>
<li>\({l = 1\ldots L\; \text{- latent variables}}\)</li>
<li>\({k = 1\ldots K\; \text{- layers}}\)</li>

</ul></li>
<li>Variables
<ul>
<li>\({x_{nd}\; \text{- observations}}\)</li>
<li>\({u_{ld}\; \text{- parameters}}\)</li>
<li>\({z_{nl}\; \text{- latent variables}}\)</li>

</ul></li>

</ul>
</section>
<section id="slide-sec-1-2">
<h3 id="sec-1-2">Model derivation</h3>
<ul>
<li data-fragment-index="1" class="fragment appear">Construct a conditional probability distribution based the hamming distance between two binary vectors, \({h(\mathbf{x},\mathbf{u})}\), and a dispersion parameter \({\lambda}\): $$ p(\mathbf{x}|\mathbf{u}) \propto \exp\left[ -\lambda \, h(\mathbf{x},\mathbf{u}) \right] $$</li>
<li data-fragment-index="2" class="fragment appear">Each observations \({\mathbf{x} }\) is generated from a subset of binary <b>codes</b>: \({\mathbf{u}_{l{=}1\ldots L}}\), selected by a vector of binary latent variables \({\mathbf{z}}\) $$ p(\mathbf{x}|\mathbf{U},\mathbf{z},\lambda) \propto \prod\limits_l p(\mathbf{x}|\mathbf{u}_l,\lambda)^{z_l} = \prod\limits_d \exp\left[- \sum_l z_l \lambda h(x_d,u_{ld}) \right]$$</li>
<li data-fragment-index="3" class="fragment appear">Normalising the likelihood for for binary observations yields a <b>logistic sigmoid</b>: $$ p(x_d = 1|\mathbf{z}, \mathbf{u}_{1\ldots L}, \lambda) = \frac{1}{1+\exp\left[-\lambda \sum\limits_l z_l (2u_{ld} - 1) \right]} = \sigma\left[-\lambda \sum_l z_l \tilde{u}_{ld} \right]$$</li>
<li data-fragment-index="4" class="fragment appear">We defined the mapping from \({\{0,1\}}\) to \({\{{-}1,1\}\,}\): \(\;\;{\tilde{u} = 2u{-}1}\)</li>

</ul>
</section>
<section id="slide-sec-1-3">
<h3 id="sec-1-3">Graphical model representation</h3>
<ul>
<li>$$ p(\mathbf{x}_{n}|\mathbf{z}_n,\mathbf{U},\lambda) = \prod_d \text{Ber}  \left( x_{nd} |\sigma \left[ \lambda \sum\limits_{l=1}^L z_{ln} \tilde{u}_{ld}  \right] \right)$$</li>

</ul>


<div class="figure">
<p><img src="single_layer_network.png" alt="single_layer_network.png" />
</p>
</div>
</section>
<section id="slide-sec-1-4">
<h3 id="sec-1-4">Toy example</h3>

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/simulation_studies/toy_tests/train_seed14_method-mmgarch-3/figures/sampler_002.png" alt="sampler_002.png" />
</p>
</div>
</section>
<section id="slide-sec-1-5">
<h3 id="sec-1-5">Toy example</h3>

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/simulation_studies/toy_tests/train_seed14_method-mmgarch-3/figures/animation.gif" alt="animation.gif" />
</p>
</div>
</section>
</section>
<section>
<section id="slide-sec-2">
<h2 id="sec-2">Synthetic example: Calculator digits</h2>

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/simulation_studies/figures/calculator/digits.png" alt="digits.png" width="70%" height="50%" />
</p>
</div>
<ul>
<li>Each digit is composed of a subset of 7 distinct bars.</li>

</ul>
</section>
<section id="slide-sec-2-1">
<h3 id="sec-2-1">Noiseless calculator digits</h3>
<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/nonsparse_noisefree_data.png" alt="nonsparse_noisefree_data.png" />
compressed data
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/nonsparse_noisefreeU0.png" alt="nonsparse_noisefreeU0.png" />
inferred codes
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/codes_recon_new.png" alt="codes_recon_new.png" />
uncompressed inferred codes
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/nonsparse_noisefreeZ0.png" alt="nonsparse_noisefreeZ0.png" />
inferred latent variables
</p>
</div>

<div class="column" style="float:left; width: 50%">
<ul class="fragment appear">
<li><b>What about 3, 8 and 9?</b>
<ul>
<li>\({``7 + 2 + 5 = 3"}\)</li>
<li>\({``7 + 2 + 5 + 6 + 1 = 3"}\)</li>

</ul></li>

</ul>
</div>

</section>
<section id="slide-sec-2-2">
<h3 id="sec-2-2">Other <i>perfect</i> solutions</h3>
<div class="column" style="float:left; width: 40%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/calc_simulations/snas714.png" alt="snas714.png" width="70%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 40%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/calc_simulations/snas715.png" alt="snas715.png" width="70%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 8%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_logs/simulation_studies/perfect_digits/cbar.png" alt="cbar.png" width="80%" height="20%" />
</p>
</div>
</div>


</section>
<section id="slide-sec-2-3">
<h3 id="sec-2-3">Reconstruction Error</h3>

<div class="figure">
<p><img src="calc_dist.png" alt="calc_dist.png" width="90%" height="20%" />
</p>
</div>

</section>
<section id="slide-sec-2-4">
<h3 id="sec-2-4">Denoising</h3>
<div class="column" style="float:left; width: 40%">
<ul>
<li>Calculator digits with 10% noise.</li>

</ul>
</div>

<div class="column" style="float:left; width: 100%">
</div>


<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/server_figs/recon_example32.png" alt="recon_example32.png" width="80%" height="20%" />
Denoised digits
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/server_figs/recon_example42.png" alt="recon_example42.png" width="80%" height="20%" />
Denoised digits
</p>
</div>


<div class="column" style="float:left; width: 30%">
<p>
<img src="file:///home/tammo/hamming_projects/server_figs/recon_example_snas.png" alt="recon_example_snas.png" width="80%" height="20%" />
Corresponding codes
</p>
</div>

</section>
</section>
<section>
<section id="slide-sec-3">
<h2 id="sec-3">The multi-layer Hamming Machine</h2>

<div class="figure">
<p><img src="twolayer_hm.png" alt="twolayer_hm.png" />
</p>
</div>

<p>
The joint density factorises in terms of the form p(layer|parents)
</p>

<p>
With \({\mathbf{z}^{[0]}_n = \mathbf{x}_n}\) and \({L^{[0]} = D}\), that is
$$  p(\mathbf{Z}^{[0:K]},\mathbf{U}^{[1:K]},\lambda) = 
  p(\mathbf{Z}^{[K]}) \prod_{k=0}^{K-1} p(\mathbf{Z}^{[k]}|\mathbf{Z}^{[k{+}1]},\mathbf{U}^{[k{+}1]},\lambda^{[k{+}1]})\, p(\mathbf{U}^{[k{+}1]})\, p(\lambda^{[k{+}1]}) 
$$
</p>
</section>
</section>
<section>
<section id="slide-sec-4">
<h2 id="sec-4">Inference and learning</h2>
<div class="outline-text-2" id="text-4">
</div></section>
<section id="slide-sec-4-1">
<h3 id="sec-4-1">Abbrevations</h3>
<ul>
<li><i>Observation count matrix</i>: $$ a_{nd} = \tilde{x}_{nd} \sum\limits_{l = 1}^{M} z_{ln} \tilde{u}_{ld} $$ $$ a_{nd} \in \{-L,\ldots,-1,0,1,\ldots,L \} $$</li>
<li>Enables us to write the likelihood: $$ \mathcal{L}(\mathbf{U},\mathbf{Z},\lambda) = \prod_{n,d} \sigma \left[ \lambda a_{nd} \right] $$</li>

</ul>
</section>
<section id="slide-sec-4-2">
<h3 id="sec-4-2">Gibbs sampling &#x2013; full conditionals</h3>
<ul>
<li>Precomputed quantities $$  \gamma_{\lambda}(l) = \log(1+e^{-\lambda l}) $$</li>
<li>Full conditionals $$  p(u_{ld}=1|\text{rest}) = \sigma \left[-\tilde{u}_{ld} \sum\limits_n \left\{ \gamma_{\lambda}(a_{nd}) - \gamma_{\lambda}(a_{nd} -  \tilde{u}_{ld} \,\tilde{x}_{nd} (\tilde{z}_{nl}+1) )\right\} \right] $$ $$ p(z_{nl}{=}1|\text{rest}) = \sigma\left[ -\tilde{z}_{ln} \sum\limits_d \left\{ \gamma_{\lambda}\left(a_{nd}\right) - \gamma_{\lambda}\left(a_{nd}-\tilde{z}_{ln}\,\tilde{x}_{nd}\,\tilde{u}_{ld}\right) \right\} \right] $$</li>
<li>Multilayer conditionals $$ p(z^{[k]}_{nl}{=}1) = \sigma\left[-\tilde{z}_{nl} \sum\limits_{d} \left\{ \log \left( 1 + \exp \left[ -\lambda a_{nd} \right] \right)
    -\log\left( 1 + \exp\left[ -\lambda (a_{nd} - \tilde{z}_{nl} \tilde{x}_{nd} \tilde{u}_{ld} \right) \right] \right)  \right. 
  \left. + \lambda^{[k+1]} \sum\limits_{l^{[k+1]}} \tilde{u}^{[k+1]}_{l^{[k+1]}l}\; z_{nl}^{[k+1]} \right] $$</li>

</ul>
</section>
<section id="slide-sec-4-3">
<h3 id="sec-4-3">The modified metropolised Gibbs sampler</h3>
<ul>
<li data-fragment-index="1" class="fragment appear">Instead of drawing from the full conditional we always propose a value \({y'}\) that is different from the current value \({y}\), i.e. \({y' = 1-y}\).</li>
<li data-fragment-index="2" class="fragment appear">The proposal distribution then takes the form $$ q(y'|y\neq y') = 1 = \frac{p(y'|\text{rest})}{1-p(y|\text{rest})} $$</li>
<li data-fragment-index="3" class="fragment appear">And the Hasting acceptance ratio, equal the mutation probability and is given by $$ p_{\text{mutation}}^{\text{modified}} = \frac{p(\mathbf{y}')q(y|y')}{p(\mathbf{y})q(y'|y)} = \frac{p(y'|\text{rest})}{1-p(y'|\text{rest})} $$</li>
<li data-fragment-index="4" class="fragment appear">The Gibbs mutation probability is given by $$ p_{\text{mutation}}^{\text{Gibbs}} = p(y'|\text{rest}) $$</li>
<li data-fragment-index="5" class="fragment appear">And therefor the modified sampler has a <b>higher mutation probability</b> $$  p_{\text{mutation}}^{\text{modified}} > p_{\text{mutation}}^{\text{Gibbs}} $$</li>

</ul>
</section>
<section id="slide-sec-4-4">
<h3 id="sec-4-4">Alternative sampling schemes</h3>
<div class="outline-text-3" id="text-4-4">
</div></section>
<section id="slide-sec-4-4-1">
<h4 id="sec-4-4-1">Approaches</h4>
<ol>
<li>Forward-filtering backward-sampling for joint updates across layers
<ul>
<li>Using coniditional independence properties, like for hidden Markov models.</li>

</ul></li>
<li>Layer-wise training
<ul>
<li>Start from the layer closest to the data</li>
<li>Train until convergence</li>
<li><i>Turn on</i> layer below</li>

</ul></li>
<li>Simulated reheating
<ul>
<li>After convergence, reheat the system by means of the dispersion parameter \(\lambda\).</li>
<li>Sample at fixed high temperature</li>
<li>Converge back to equilibrium temperature</li>

</ul></li>
<li>Parallel tempering
<ul>
<li>Swapping states between chains is extremely unlikely</li>

</ul></li>

</ol>
</section>
<section id="slide-sec-4-4-2">
<h4 id="sec-4-4-2">Results</h4>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/improve_inference/shared_logs/comparsion_overall.png" alt="comparsion_overall.png" width="65%" height="20%" />
</p>
</div>

<p>
Joint \({p(\mathbf{X},\mathbf{Z}_1,\mathbf{Z}_2|\mathbf{U},\lambda_0)}\)
</p>
</div>

<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/improve_inference/shared_logs/comparsion_layer1.png" alt="comparsion_layer1.png" width="65%" height="20%" />
</p>
</div>

<p>
Data layer \({p(\mathbf{X}|\mathbf{Z}_1,\mathbf{U},\lambda_1)}\)
</p>
</div>

<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/improve_inference/shared_logs/comparsion_layer2.png" alt="comparsion_layer2.png" width="65%" height="20%" />
</p>
</div>

<p>
Data layer \({p(\mathbf{Z}_1|\mathbf{Z}_2,\mathbf{U},\lambda_2)}\)
</p>
</div>

<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/improve_inference/shared_logs/comparsion_layer3.png" alt="comparsion_layer3.png" width="65%" height="20%" />
</p>
</div>

<p>
Data layer \({p(\mathbf{Z}_2|\mathbf{Z}_3,\mathbf{U},\lambda_3)}\)
</p>
</div>

</section>
</section>
<section>
<section id="slide-sec-5">
<h2 id="sec-5">Priors on the codes</h2>
<div class="outline-text-2" id="text-5">
</div></section>
<section id="slide-sec-5-1">
<h3 id="sec-5-1">Effect on the conditionals</h3>
<ul>
<li>A Bernoulli prior on a single code unit \({u_{ld}}\):</li>

</ul>
<p>
$$ p(u_{ld}=1|\text{rest}) = \sigma \left[\color{red}{ \log\left(  \frac{ p(u_{ld}) }{ 1 - p(u_{ld}) } \right)} - \tilde{u}_{ld} \sum\limits_n \left\{ \gamma_{\lambda}(a_{nd}) - \gamma_{\lambda}(a_{nd} - \tilde{u}_{ld}\,\tilde{x}_{nd} (\tilde{s}_{mn} + 1))\right\} \right] $$
</p>

</section>
<section id="slide-sec-5-2">
<h3 id="sec-5-2">Types of priors</h3>
<div class="column" style="float:left; width: 55%">
<ol>
<li>Independent Bernoulli prior on every single code unit \({u_{md}}\)</li>
<li>Bernoulli prior controlling the number of 1s in every code. q is the ratio of 1s in code to 1s in data.</li>

</ol>
</div>

<div class="column" style="float:left; width: 100%">
<p>
E.g. <i>step-exp prior</i>
</p>
</div>

<p>
<img src="figures/prior.png" alt="prior.png" />
$$  p(u = 1) = \tfrac{1}{2} \mathrm{H}( 1 - q ) + \tfrac{1}{2} \mathrm{H}(q-1) e^{-a(q-1)} $$
</p>
</section>
<section id="slide-sec-5-3">
<h3 id="sec-5-3">Effect of the prior for synthetic data - flat prior (old example)</h3>

<div class="figure">
<p><img src="figures/a4_10_5.gif" alt="a4_10_5.gif" />
</p>
</div>
</section>
<section id="slide-sec-5-4">
<h3 id="sec-5-4">Effect of the prior for synthetic data - step exp sparsity prior</h3>

<div class="figure">
<p><img src="figures/a4_10_5_sparse.gif" alt="a4_10_5_sparse.gif" />
</p>
</div>
</section>
</section>
<section>
<section id="slide-sec-6">
<h2 id="sec-6">Cancer mutational landscapes</h2>
<div class="outline-text-2" id="text-6">
</div></section>
<section id="slide-sec-6-1">
<h3 id="sec-6-1">First hidden layer</h3>
<div class="column" style="float:left; width: 72%">

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm0.png" alt="latent_hm0.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm2.png" alt="latent_hm2.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm1.png" alt="latent_hm1.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm3.png" alt="latent_hm3.png" width="100%" height="20%" />
</p>
</div>
</div>
<ul>
<li>Test Test Test Test Test Test Test Test Test Test Test</li>

</ul>
</div>

<div class="column" style="float:left; width: 28%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/snas_0.png" alt="snas_0.png" width="70%" height="20%" />
</p>
</div>
</div>

</section>
<section id="slide-sec-6-2">
<h3 id="sec-6-2">Second hidden layer</h3>
<div class="column" style="float:left; width: 72%">

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm0_0.png" alt="latent_hm0_0.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm2_0.png" alt="latent_hm2_0.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm1_0.png" alt="latent_hm1_0.png" width="100%" height="20%" />
</p>
</div>
</div>

<div class="column" style="float:left; width: 25%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/latent_hm3_0.png" alt="latent_hm3_0.png" width="100%" height="20%" />
</p>
</div>
</div>
<ul>
<li>Test Test Test Test Test Test Test Test Test Test Test</li>

</ul>
</div>

<div class="column" style="float:left; width: 28%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/snas_1.png" alt="snas_1.png" width="75%" height="20%" />
</p>
</div>
</div>
</section>
<section id="slide-sec-6-3">
<h3 id="sec-6-3">PCA</h3>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/pca_0.png" alt="pca_0.png" />
</p>
</div>
</div>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/pca_1.png" alt="pca_1.png" />
</p>
</div>
</div>
</section>
<section id="slide-sec-6-4">
<h3 id="sec-6-4">tSNE</h3>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/tsne_0.png" alt="tsne_0.png" width="130%" height="100%" />
</p>
</div>
</div>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/gabor/pancan/tsne_1.png" alt="tsne_1.png" width="130%" height="1000%" />
</p>
</div>
</div>
</section>
<section id="slide-sec-6-5">
<h3 id="sec-6-5">Comparison to binary PCA</h3>
</section>
</section>
<section>
<section id="slide-sec-7">
<h2 id="sec-7">The sparse Hamming Machine</h2>
<div class="outline-text-2" id="text-7">
</div></section>
<section id="slide-sec-7-1">
<h3 id="sec-7-1">Motivation</h3>
<ul>
<li>The <i>problem</i>: Every code has to vote on every feature. If a code believes that certain features appear together, than it necessarily provides the same evidence for all other features to no appear.</li>
<li>This may not reflect the generative process that we wish to capture.</li>
<li>Proposed modification: $$ \tilde{u} \in \{-1,1\} \;\; \rightarrow \;\; \tilde{u} \in \{-1,0,1\} $$</li>
<li>This yields the full conditional: $$   p(\tilde{u}_{ld}|\text{rest}) =
   \text{Cat} \left( \underset{\tilde{u}' \in \{-1,0,1\}}{\mathcal{S}} \left[ - \sum\limits_n \gamma_{\lambda}(a_{nd,\tilde{u}'}) \right] \right) $$</li>

</ul>
</section>
<section id="slide-sec-7-2">
<h3 id="sec-7-2">Synthetic example</h3>
<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/gabor/sparse_Hm/nonsparse_noisy_newdata.png" alt="nonsparse_noisy_newdata.png" />
compressed data
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/gabor/sparse_Hm/calc_digits_codesviva.png" alt="calc_digits_codesviva.png" />
inferred codes
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/gabor/sparse_Hm/calc_digits_sparse_codes_reconviva.png" alt="calc_digits_sparse_codes_reconviva.png" />
reconstruction of codes
</p>
</div>

<div class="column" style="float:left; width: 25%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/gabor/sparse_Hm/nonsparse_noisy_newZ0.png" alt="nonsparse_noisy_newZ0.png" />
latent variables
</p>

</div>

<div class="column" style="float:left; width: 20%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/gabor/sparse_Hm/calc_digits_sparse_codes_reconviva_3.png" alt="calc_digits_sparse_codes_reconviva_3.png" />
codes for \({L{=}3}\)
</p>
</div>

<div class="column" style="float:left; width: 20%">
<p>
<img src="file:///home/tammo/hamming_projects/local_figs/rgb_simplex.png" alt="rgb_simplex.png" />
color legend
</p>
</div>

<div class="column" style="float:left; width: 60%">

<ul>
<li>Latent representation are sparser than for the traditional HM</li>
<li>The <i>obvious</i> single-bar representation takes L=14 codes.</li>

</ul>
</div>

</section>
<section id="slide-sec-7-3">
<h3 id="sec-7-3">Reconstruction error</h3>

<div class="figure">
<p><img src="file:///home/tammo/hamming_projects/local_figs/blackgoose/distr.png" alt="distr.png" width="80%" height="50%" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-sec-8">
<h2 id="sec-8">Future work</h2>
<div class="outline-text-2" id="text-8">
</div></section>
<section id="slide-sec-8-1">
<h3 id="sec-8-1">The minimal Hamming Machine</h3>
<ul>
<li>A very intuitive way of combining codes to generate observations. $$  p(x_{nd}=1|\mathbf{u}_d,\mathbf{z}_n) \propto \exp\left[{\lambda\, h(x,\min(\mathbf{u}^T\mathbf{z},1))} \right] $$</li>
<li>The binomial parameter for node \(x_{nd}\) takes one of only 2 possible values, \({\sigma(\pm \lambda)}\).
<ul>
<li>It equals \({\sigma(+\lambda)}\) if a single pair of its parent variables is <i>turned on</i>, \((z_{nl},u_{ld}) = (1,1)\), indepedent of the value of all other parents.</li>
<li>It equald \({-\lambda}\) if all parents are <i>turned off</i>.</li>

</ul></li>

</ul>
</section>
<section id="slide-sec-8-2">
<h3 id="sec-8-2">Scalable inference</h3>
<div class="outline-text-3" id="text-8-2">
</div></section>
<section id="slide-sec-8-2-1">
<h4 id="sec-8-2-1">Simple fixed point equations</h4>
<ul>
<li>Break the <i>explaining away</i> dependency between the latent variables. $$ p(\mathbf{x}|\mathbf{z},\mathbf{u}) \approx \prod\limits_{d,l} \sigma\left[ \lambda x_{d} z_l \tilde{u}_{ld}  \right] $$</li>
<li>Iterate through all \(z_{nl}\) and \(u_{ld}\) and optimise every single one $$   \sum\limits_d \tilde{x}_{nd} \tilde{u}_{ld} + \sum\limits_{l^{[2]}} z^{[2]}_{nl} \tilde{u}^{[2]}_{ld} > 0 \; \rightarrow z_{nl} = 1,\; \text{else}\; z_{nl}=0 $$ $$  \sum\limits_n \tilde{x}_{nd} z_{nl} > 0 \; \rightarrow u_{ld} = 1,\; \text{else}\; u_{ld}=0 $$</li>
<li>This will converge very quickly but depend heavily on the intial conditions.</li>

</ul>
</section>
<section id="slide-sec-8-3">
<h3 id="sec-8-3">Further applications</h3>
<ul>
<li>Networks
<ul>
<li>Adjacency matrices as input, e.g. brain networks from EEG/fMRI for different timepoints or different individuals.</li>
<li>Binarised single cell expression data.</li>
<li>Hannah/Garrett?</li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="slide-sec-9">
<h2 id="sec-9">Appendix A: Further example &#x2013; MNIST</h2>
<ul>
<li>200 images of the units 2, 7, 9</li>
<li>Two hidden layers, with 30 and 6 units respectively.</li>

</ul>
</section>
<section id="slide-sec-9-1">
<h3 id="sec-9-1">Sampling</h3>

<div class="figure">
<p><img src="figures/mnist_sampler.png" alt="mnist_sampler.png" />
</p>
</div>
</section>
<section id="slide-sec-9-2">
<h3 id="sec-9-2">Reconstructions</h3>
<p>
From the corresponding representations in layer 1 (left) and layer 2 (right)
</p>

<p>
<img src="figures/recon_1.png" alt="recon_1.png" />
<img src="figures/recon_2.png" alt="recon_2.png" />
</p>
</section>
<section id="slide-sec-9-3">
<h3 id="sec-9-3">Codes</h3>

<div class="figure">
<p><img src="figures/snb_small_1.png" alt="snb_small_1.png" />
</p>
</div>
</section>
<section id="slide-sec-9-4">
<h3 id="sec-9-4">Codes</h3>

<div class="figure">
<p><img src="figures/snb_small_2.png" alt="snb_small_2.png" />
</p>
</div>
</section>
</section>
</div>
</div>

<script src="/home/tammo/Dropbox/templates/org_reveal_presentation/lib/js/head.min.js"></script>
<script src="/home/tammo/Dropbox/templates/org_reveal_presentation/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: true,
rollingLinks: true,
keyboard: true,
overview: true,
width: 1920,
height: 1080,
margin: 0.15,
minScale: 0.50,
maxScale: 2.00,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'cube', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'default',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: '/home/tammo/Dropbox/templates/org_reveal_presentation/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
 { src: '/home/tammo/Dropbox/templates/org_reveal_presentation/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '/home/tammo/Dropbox/templates/org_reveal_presentation/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '/home/tammo/Dropbox/templates/org_reveal_presentation/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
]
});
</script>
</body>
</html>
